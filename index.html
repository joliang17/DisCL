<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <meta name="title" content="Diffusion Curriculum (DisCL): Synthetic-to-Real Data Curriculum via Image-Guided Diffusion - Yijun Liang, Shweta Bhardwaj, Tianyi Zhou">
  <meta name="description" content="We propose Diffusion Curriculum (DisCL), a framework that uses image-guided diffusion to generate a spectrum of synthetic-to-real data for curriculum learning. By progressively adjusting image guidance, DisCL improves learning on hard and scarce samples. Experiments show significant gains on long-tail classification and low-quality data, including large boosts in tail-class and OOD accuracy.">
  <meta name="keywords" content="Curriculum Learning, Machine Learning, Computer Vision, AI">
  <meta name="author" content="Yijun Liang, Shweta Bhardwaj, Tianyi Zhou">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="Diffusion Curriculum (DisCL): Synthetic-to-Real Data Curriculum via Image-Guided Diffusion">
  <meta name="citation_author" content="Liang, Yijun">
  <meta name="citation_author" content="Bhardwaj, Shweta">
  <meta name="citation_author" content="Zhou, Tianyi">
  <meta name="citation_publication_date" content="2025">
  <meta name="citation_conference_title" content="ICCV">
  <meta name="citation_pdf_url" content="https://arxiv.org/pdf/2410.13674">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <title>DisCL: Synthetic-to-Real Generative Curriculum Learning via Image-Guided Diffusion</title>

  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  <script>
  window.MathJax = {
    tex: {inlineMath: [['$', '$'], ['\\(', '\\)']]},
    svg: {fontCache: 'global'}
  };
</script>
<script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "Diffusion Curriculum: Synthetic-to-Real Data Curriculum via Image-Guided Diffusion",
    "author": [
      {
        "@type": "Person",
        "name": "Yijun Liang",
        "affiliation": {
          "@type": "Organization",
          "name": "University of Maryland, College Park"
        }
      },
      {
        "@type": "Person",
        "name": "Shweta Bhardwaj",
        "affiliation": {
          "@type": "Organization",
          "name": "University of Maryland, College Park"
        }
      },
      {
        "@type": "Person",
        "name": "Tianyi Zhou",
        "affiliation": {
          "@type": "Organization",
          "name": "University of Maryland, College Park"
        }
      }
    ],
    "datePublished": "2025-10-01",
    "publisher": {
      "@type": "Organization",
      "name": "ICCV2025"
    },
    "url": "https://joliang17.github.io/",
    "keywords": ["Curriculum Learning", "Machine Learning", "Computer Vision", "AI"],
    "abstract": "Low-quality or scarce data has posed significant challenges for training deep neural networks in practice. While classical data augmentation cannot contribute very different new data, diffusion models opens up a new door to build self-evolving AI by generating high-quality and diverse synthetic data through text-guided prompts. However, text-only guidance cannot control synthetic images' proximity to the original images, resulting in out-of-distribution data detrimental to the model performance. To overcome the limitation, we study image guidance to achieve a spectrum of interpolations between synthetic and real images. With stronger image guidance, the generated images are similar to the training data but hard to learn. While with weaker image guidance, the synthetic images will be easier for model but contribute to a larger distribution gap with the original data. The generated full spectrum of data enables us to build a novel 'Diffusion Curriculum (DisCL)'. DisCL adjusts the image guidance level of image synthesis for each training stage: It identifies and focuses on hard samples for the model and assesses the most effective guidance level of synthetic images to improve hard data learning. We apply DisCL to two challenging tasks: long-tail (LT) classification and learning from low-quality data. It focuses on lower-guidance images of high-quality to learn prototypical features as a warm-up of learning higher-guidance images that might be weak on diversity or quality. Extensive experiments showcase a gain of 2.7% and 2.1% in OOD and ID macro-accuracy when applying DisCL to iWildCam dataset. On ImageNet-LT, DisCL improves the base model's tail-class accuracy from 4.4% to 23.64% and leads to a 4.02% improvement in all-class accuracy.",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://joliang17.github.io/DisCL/"
    }
  }
  </script>

</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>


  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Diffusion Curriculum: Synthetic-to-Real Data Curriculum via Image-Guided Diffusion</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://joliang17.github.io/" target="_blank">Yijun Liang</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="https://shwetabhardwaj44.github.io/" target="_blank">Shweta Bhardwaj</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="https://tianyizhou.github.io/" target="_blank">Tianyi Zhou</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">University of Maryland, College Park<br>ICCV 2025</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2410.13674" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <span class="link-block">
                    <a href="https://github.com/tianyi-lab/DisCL" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="https://arxiv.org/abs/2410.13674" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/cases.png" alt="Spectrum of Images generated with image guidance" loading="lazy"/>
      <h2 class="subtitle has-text-centered">
        Spectrum of Images generated with image guidance
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Low-quality or scarce data has posed significant challenges for training deep neural networks in practice. While classical data augmentation cannot contribute very different new data, diffusion models opens up a new door to build self-evolving AI by generating high-quality and diverse synthetic data through text-guided prompts. However, text-only guidance cannot control synthetic images' proximity to the original images, resulting in out-of-distribution data detrimental to the model performance. To overcome the limitation, we study image guidance to achieve a spectrum of interpolations between synthetic and real images. With stronger image guidance, the generated images are similar to the training data but hard to learn. While with weaker image guidance, the synthetic images will be easier for model but contribute to a larger distribution gap with the original data. The generated full spectrum of data enables us to build a novel "Diffusion Curriculum (DisCL)". DisCL adjusts the image guidance level of image synthesis for each training stage: It identifies and focuses on hard samples for the model and assesses the most effective guidance level of synthetic images to improve hard data learning. We apply DisCL to two challenging tasks: long-tail (LT) classification and learning from low-quality data. It focuses on lower-guidance images of high-quality to learn prototypical features as a warm-up of learning higher-guidance images that might be weak on diversity or quality. Extensive experiments showcase a gain of 2.7% and 2.1% in OOD and ID macro-accuracy when applying DisCL to iWildCam dataset. On ImageNet-LT, DisCL improves the base model's tail-class accuracy from 4.4% to 23.64% and leads to a 4.02% improvement in all-class accuracy.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        <div class="content has-text-justified">
          <img src="static/images/overview.png" alt="Overview" loading="lazy"/>
          <p>DisCL includes two phases: <b>(Phase 1)</b> Syn-to-Real Data Generation & <b>(Phase 2)</b> Generative Curriculum Learning.</p>

           <p> In Phase 1, we identify “hard” samples in the training set and use them as guidance to generate a spectrum of synthetic-to-real images by varying image guidance strength $\lambda$.</p>

            <p>In Phase 2, a curriculum (Adaptive or Non-Adaptive) selects guidance levels $\lambda_i$ at each stage. Adaptive schedules maximize expected progress, while Non-Adaptive follows a preset plan. Then according to corresponding schedules, selected synthetic data is combined with real samples to train the model.</p>
        </div>
      </div>
    </div>
  </div>
</section>



<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
      <div class="item">
        <img src="static/images/ImageNet-LT_2.png" alt="ImageNet-Longtail 2" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          Synthetic images on ImageNet-LT dataset.
        </h2>
      </div>
      <div class="item">
        <img src="static/images/ImageNet-LT_3.png" alt="ImageNet-Longtail 3" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          Synthetic images on ImageNet-LT dataset.
        </h2>
      </div>
      <div class="item">
        <img src="static/images/ImageNet-LT_4.png" alt="ImageNet-Longtail 4" loading="lazy" style="max-height:500px; width:auto; margin:auto; display:block;"/>
        <h2 class="subtitle has-text-centered">
          Synthetic images on ImageNet-LT dataset.
        </h2>
      </div>
      <div class="item">
        <img src="static/images/iWildCam_1.png" alt="iWildCam 1" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          Synthetic images on iWildCam dataset.
        </h2>
      </div>
      <div class="item">
        <img src="static/images/iWildCam_2.png" alt="iWildCam 2" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          Synthetic images on iWildCam dataset.
        </h2>
      </div>
      <div class="item">
        <img src="static/images/iWildCam_3.png" alt="iWildCam 3" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          Synthetic images on iWildCam dataset.
        </h2>
      </div>
      <div class="item">
        <img src="static/images/iWildCam_4.png" alt="iWildCam 4" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          Synthetic images on iWildCam dataset.
        </h2>
      </div>
      <div class="item">
        <img src="static/images/Cifar100_1.png" alt="Cifar 1" loading="lazy" style="max-width:600px; height:auto; margin:auto; display:block;"/>
        <h2 class="subtitle has-text-centered">
          Synthetic images on CIFAR-100 dataset.
        </h2>
      </div>
      <div class="item">
        <img src="static/images/iNaturalist_1.png" alt="iNaturalist 1" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          Synthetic images on iNaturalist dataset.
        </h2>
      </div>
  </div>
    </div>
  </div>
</section>
<!-- End image carousel -->


<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Curriculum Strategies</h2>
        <div class="content has-text-justified">
          <div class="columns is-variable is-5">
            <!-- Left -->
            <div class="column">
              <div class="plot-card">
                <figure class="plot-figure">
                  <img src="static/images/non_adaptive.png"
                       alt="Non Adaptive Curriculum"
                       loading="lazy"/>
                </figure>
                <p class="has-text-grey"><b>Non-adaptive Curriculum Strategy</b>:</p>
                <p class="has-text-grey is-size-6">First expose the model to diverse synthetic images of tail classes, and then progressively shift to a task-specific distribution that resembles the original images.</p>
              </div>
            </div>

            <!-- Right -->
            <div class="column">
              <div class="plot-card">
                <figure class="plot-figure">
                  <img src="static/images/adaptive.png"
                       alt="Adaptive Curriculum"
                       loading="lazy"/>
                </figure>
                <p class="has-text-grey"><b>Adaptive Curriculum Strategy</b>:</p>
                <p class="has-text-grey is-size-6">Selects the image guidance level $\lambda$ at each epoch based on progress (defined by improvement in ground-truth class confidence on validation subsets corresponding to each $\lambda$). The guidance level with the highest progress is chosen for the next epoch's training.</p>
              </div>
            </div>
          </div> <!-- /columns -->
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Experiment Result</h2>
        <h2 class="title is-4">Learning from Long-Tail Data</h2>
        <div class="container">
          <div id="results-carousel_lt" class="carousel results-carousel">
          <div class="item">
            <img src="static/images/imagenet_ablation.png" alt="ImageNet-Longtail Results" loading="lazy"/>
            <h2 class="subtitle has-text-centered">
              DisCL performance and result of ablation study on ImageNet-LT dataset.
            </h2>
          </div>
          <div class="item">
            <img src="static/images/inat.png" alt="INaturalist Results" loading="lazy" style="max-height:200px; width:auto; margin:auto; display:block;"/>
            <h2 class="subtitle has-text-centered">
              DisCL performance on iNaturalist dataset.
            </h2>
          </div>
          <div class="item">
            <img src="static/images/cifar.png" alt="Cifar Results" loading="lazy" style="max-height:500px; width:auto; margin:auto; display:block;"/>
            <h2 class="subtitle has-text-centered">
              DisCL performance on CIFAR-100 dataset.
            </h2>
          </div>
        </div>
        </div>

        <h2 class="title is-4">Learning from Low-quality Data</h2>
        <div class="hover-card">
          <img src="static/images/iwildcam_ablation.png" alt="iWildCam Results"  loading="lazy"  style="max-height:400px; width:auto; margin:auto; display:block;" />
          <h2 class="subtitle has-text-centered">
            DisCL performance and result of ablation study on iWildCam dataset.
          </h2>
        </div>
        <div class="content has-text-justified">
          <p>Across <b>long-tail</b> benchmarks (ImageNet-LT, iNaturalist, CIFAR-100) and <b>low-quality</b> data (iWildCam), DisCL consistently boosts both tail-class and overall accuracy across various base model settings. Through the comprehensive ablation study, our analyses reveal that the interpolation of synthetic-to-real data, the selection of guidance intervals, and the proposed curriculum strategy are all essential components contributing to these gains. </p>
        </div>
      </div>
    </div>
  </div>
</section>



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@inproceedings{liang-bhardwaj-zhou-2024-discl,
    title = "Diffusion Curriculum: Synthetic-to-Real Data Curriculum via Image-Guided Diffusion",
    author = "Liang, Yijun and Bhardwaj, Shweta and Zhou, Tianyi",
    booktitle = "International Conference on Computer Vision (ICCV)",
    year = "2025",
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
